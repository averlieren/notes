\documentclass[twoside]{report}
\usepackage{brandon}

\course{MATH 308}
\sect{524}
\class{Differential Equations}
\textbook{Elementary Differential Equations, 11\textsuperscript{th} Edition}
\name{Brandon Nguyen}

\begin{document}
    \maketitle
    \tableofcontents
    \np

    \chapter{14 January 2020}
    \section{First Order Differential Equations}
    \begin{definition}[First Order Differential Equation]
        The generic form of a \textbf{first order differential equation} is \begin{equation}
            y' = f(x, y)
        \end{equation}
        Sometimes, $t$ is substituted for $x$, especially if the function relates to time.
    \end{definition}
    \begin{definition}[General Solution]
        A solution to a differential equation is considered to be \textbf{general} if there is an arbitrary constant present in the final answer, i.e. a problem without initial values.
    \end{definition}
    \begin{example}
        \begin{alignat}{1}
            y' &= 1\\
            y &= \int y'\,dx\\
            &= 1\,dx\\
            &= x + C
        \end{alignat}
    \end{example}
    \np
    \begin{definition}[Open Differential Equations]
        Equations without solutions are considered to be \textbf{open}. Many differential equations are without solutions.
    \end{definition}
    \begin{example}[Open Differential Equation]
        \begin{equation}
            y' = x'y - x^{3}
        \end{equation}
        This differential equation does not have a solution; thusly open.
    \end{example}
    \begin{example}
        \begin{equation}
            y' = y
        \end{equation}
        \begin{equation}
            \int y'\,dy = \int y\,dy \notLeftrightarrow y' = y
        \end{equation}
        Notice above that the integration of both sides is not the same as the differential equation.
        \begin{equation}
            y' = e^x \implies y \int y'\,dx = \int e^x\,dx
        \end{equation}
        Using the above, the general solution can be found
        \begin{equation}
            y = Ce^{x}
        \end{equation}
    \end{example}
    \begin{remark}[Regarding Example 1.3]
        If both sides of a differential equation are dependent on the same variable --- i.e. the same variable appearing on both sides of the equation, then taking the intergal of both sides is not a valid method to solve the equation.
    \end{remark}
    \begin{definition}[Initial Value Problems]
        An \textbf{initial value problem} (IVP), or \textbf{initial condition problem}, is a problem where an initial condition of the equation is defined which leads to a \textbf{unique solution} to the equation.
    \end{definition}
    \np
    \begin{example}[Initial Value Problem]
        \begin{equation}
            y' = x,\ y(0) = 1
        \end{equation}
        Notice that this is an \textbf{initial value problem}, because $y(0) = 1$. Also notice that $y$ is an anti-derivative w.r.t. $x$; because each side of the equation is independent of one another (unlike \emph{Example 1.3}).
        \begin{alignat}{3}
            &&\int y'\,dx &= \int x\,dx\\
            &\implies & y &= \frac{1}{2}x^{2} + C\\
            &&y(0) &= 1\\
            &\implies&=&\frac{1}{2}(0^2) + C\\
            &\implies&C&=1\\
            &\implies&y&=\frac{1}{2}x^{2} + 1
        \end{alignat}
    \end{example}
    \section{Differentiable Functions}
    \begin{definition}[Differentiability]
        Given $f: \RR \to \RR$ and point $a$, $\exists f'(a) \iff \exists T_{1}(a)$, where $T_1$ is a tangent line (Taylor polynomial of degree one).
        \begin{center}
            \begin{tikzpicture}
                \draw[<->] (-1,0) -- (5,0) node[right] {$x$};
                \draw[<->] (0,-1) -- (0,5) node[above] {$y$};
                \draw[red,<->] (-1,1.625) --(1,1.625);
                \node[red,label={[xshift=5]A}] at (0,1.6) {\textbullet};
                \node[black,label={B}] at (2.6,.585) {\textbullet};
                \draw[scale = .65, domain=-1:4,smooth,variable=\x,blue] plot ({\x}, {-.1*\x*\x+2.5});
                \draw[scale = .65, domain=4:8,smooth,variable=\x,blue] plot ({\x}, {-.1*(\x-14)*(\x-14)+10.9});
            \end{tikzpicture}
        \end{center}
        In the example, point A has a singular tangent line and is therefore differentiable. Point B has infinitely many tangent lines, and is therefore both undefined and not differentiable.
    \end{definition}
    \np
    \section{Kinematics}
    \begin{example}[Kinematics with Differential Equations]
        Given an object with a velocity $v_0$, and acceleration $a$, find the position $s$ at any time $t$.
        \begin{alignat}{3}
            &&\frac{d}{dt}v(t) &= a\\
            &\implies &v(t) &= \int a\,dt\\
            &&&= at + C\\
            &\because & v(0) &= v_{0}\\
            &&v_{0} &= a(0) + C\\
            &&C &= v_{0}\\
            &&\frac{d}{dt}s(t) &= \int v\,dt\\
            &\implies& s(t) &= \int v\,dt\\
            &&&= \int (at + v_{0})\,dt\\
            &&&= \frac{1}{2}a t^{2} + v_{0}t
        \end{alignat}
    \end{example}
    \chapter{16 January 2020}
    \section{Linear Differential Equations}
    \begin{definition}[First Order Linear Differential Equations]
        \begin{equation}
            \underbrace{y' + p(t)y = g(t)}_\text{\tiny Usual form}\iff y' = g(t) - p(t)y
        \end{equation}
        A \textbf{first order linear differential equation} (LDE) is linear due to $y$ being dependent on only one variable, $t$.
    \end{definition}
    Notice that $t$ is typically used in place of $x$ as most differential equations are used in models dependent on time; as such, most differential equations are in the form $y' = f(t, y)$ as opposed to $y' = f(x, y)$.
    \begin{example}
        \begin{alignat}{3}
            &\text{Solve } &(4 + t^{2})y' + 2ty &= 4t\\
            &\text{Notice: }&(4y + t^{2}y)' &= \frac{d}{dt}(4y + t^{2}y) = 4t\\
            &&&= 4y' + (t^{2}y)^{2}\\
            &&&= 4y' + (2ty + t^{2}y')\\
            &&&= (4 + t^2)y' + 2ty
        \end{alignat}
        The original problem can now be reduced to:
        \begin{alignat}{3}
            &&\frac{d}{dt}(4y + t^2y)&= 4t\\
            &&\text{let\quad}z(t) &= 4y + t^{2}y\\
            &&&= 2 t^{2} + C\\
            &\implies& 4y + t^{2}y &= 2 t^{2}+C\\
            &\therefore& y &= \frac{1}{4+t^{2}}(2 t^{2}+C)
        \end{alignat}
    \end{example}
    \begin{remark}[Constants]
        Notice in the above example that the constant, $C$, is being multiplied by $\frac{1}{4 + t^{2}}$. When expanding the answer, it now becomes $y = \frac{2t^{2}}{4+t^{2}} + \frac{C}{4+t^{2}}$. Notice how the constant is dependent on the variable $t$, and is therefore not the same as just $C$.
    \end{remark}
    \begin{definition}[Integrating Factors with LDEs]
        An \textbf{integrating factor}, $\mu(t)$ is a function $\mu(t): \RR \to \RR$, that satisfies $\frac{d}{dt}\mu(t) = \mu(t)y'+\mu(t)p(t)y$.
    \end{definition}
    \begin{remark}
        There are infinitely many integrating factors due to the arbitrary constant $C$ from indefinite integration, see \textbf{Method 2.1} and \textbf{Example 2.2} on the following page.
    \end{remark}
    \np
    \begin{method}[Solution of the General LDE Case]
        Solve $y' + p(t)y = g(t)$.
        \begin{enumerate}
            \item Multiply the LDE by $\mu(t)$ results in:
                \begin{equation}
                    \mu(t)(y' + p(t)y) = \mu(t)g(t)
                \end{equation}
            \item Letting $z(t) = \mu(t)y$, and $z' = \mu(t)g(t)$ yields:
                \begin{align}
                    z(t) &= \int \mu(t)g(t)\,dt\\
                    \implies y(t) &= \frac{1}{\mu(t)}\int \mu(t)g(t)\,dt\\
                    \implies \mu(t) &= \exp\BBp{\int p(t)\,dt}
                \end{align}
            \item Therefore the solution of the general case is
                \begin{equation}
                    y(t) = \BBp{\exp\Bp{\int p(t)\,dt}}^{-1}\cdot \int \exp\Bp{\int p(t)\,dt}g(t)\,dt
                \end{equation}
        \end{enumerate}
    \end{method}
    \begin{example}[Solving an IVP involving LDEs]
        Working with example 2.1.4 from the textbook:
        \begin{equation}
            ty' +4 2y = 4 t^{2},\ y(1) = 2
        \end{equation}
        \begin{enumerate}
            \item Compute the integrating factor ($\mu(t)$)
                \begin{align}
                    \mu(t) &= \exp\bbbp{\int p(t)\,dt}\\
                    &= \exp\bbbp{\int 2 t^{-1}\,dt}\\
                    &= \exp\bp{2\ln(t) + C} \Leftrightarrow e^{2\ln(t) + C}
                \end{align}
            \item Find the general case\\
                When solving, $0$ can be subsituted in for $C$ to simplify calculations; for $C \neq 0$ it is trivially shown that the constant will cancel out in computing the solution.
                \begin{align}
                    y_c(t) &= \frac{1}{\mu(t)}\int \mu(t)g(t)\,dt\\
                    &= \frac{1}{t^{2}}\bbbp{\int t^{2}\cdot 4t\,dt}\\
                    &= \frac{1}{t^{2}}(t^{4} + C)
                \end{align}
                \textbf{Note:} $y_c(t)$ is used to denote the general case.
            \item Find formula w.r.t. intial value
                \begin{alignat}{3}
                    &&y(1) &= 2\\
                    &\implies &y(1) &= (1)^{2} + \frac{C}{(1)^{2}}\\
                    &\implies &C &= 1\\
                    &\therefore &y(t) &= t^{2} + t^{-2}
                \end{alignat}
        \end{enumerate}
    \end{example}
    \chapter{21 January 2020}
    \section{Linear Differential Equations (cont).}
    \begin{example}
        Given $y'-2y=t^{2}e^{2t}$ find:
        \begin{enumerate}
            \item The general solution
            \begin{align}
                p(t) = -2,&\ g(t) = t^{2}e^{2t}\\
                \mu(t) %&= \exp\bbbp{\int p(t)\,dt}\\
                &= \exp\bbbp{\int -2\,dt}\\
                &= e^{-2t+C}\\
                y_c(t) &= e^{2t}\int t^{2}\,dt\\
                &= e^{2t}\BBp{\frac{1}{3}t^{3} + C}
            \end{align}
            \item What is $\lim_{t \rightarrow \infty} y_c(t)$?\\
            There are infinitely many $y_c(t)$; the answer may vary with the value of $C$. In this case, the value of $C$ does not matter.
            $$\lim_{t \rightarrow \infty} y_{c}(t) = +\infty$$
        \end{enumerate}
    \end{example}
    \np
    \section{Separable Differential Equations}
    \begin{definition}[Separable Differential Equations]
        A \textbf{separable differential equation} (SDE) can be defined by
        \begin{equation}
            \frac{dy}{dx}=y'=f(x, y)=-\frac{M(x, y)}{N(x, y)}
        \end{equation}
        where
        \begin{align}
            M(x, y) &= - f(x, y)\\
            N(x, y) &= 1
        \end{align}
        it is \textbf{separable} because it can be written in the \textbf{differential form}
        \begin{equation}
            M(x)\,dx+N(y)\,dy=0
        \end{equation}
    \end{definition}
    \begin{btheorem}
        If $\frac{dy}{dx} = \frac{M(x)}{N(y)}$, then $\int N(y)\,dy=\int M(x)\,dx$
    \end{btheorem}
    \begin{bproof}
        Choose $\widetilde{N}$ such that $\frac{d\widetilde{N}(y)}{dx} = M(x)$:
    \begin{align}
        \frac{d\widetilde{N}(y)}{dy} = \frac{d\widetilde{N}(y)}{dx}\frac{dx}{dy} &= \frac{d\widetilde{N}(y)}{dy}\frac{dy}{dx}= \frac{d\widetilde{N}(x)}{dx}\\
        \frac{d\widetilde{N}(y)}{dy} &= \frac{dy}{dx}
        \\
        \implies \frac{d\widetilde{N}(y)}{dx} &= M(x)
    \end{align}
    \end{bproof}
    \np
    \begin{example}
        Find a particular solution that passes through the point $(0, 1)$.
        \begin{align}
            \frac{dy}{dx} &= \frac{4x-x^{3}}{4 + y}\\
            \implies \int (4 + y)\,dy &= \int(4x-x^{3})\,dx\\
            4y+\frac{1}{2}y^{2} + C_1 &= 2 x^{2}-\frac{1}{4}x^{4} + C_2\\
            4y + \frac{1}{2} y^{2} &= 2 x^{2} - \frac{1}{4} x^{4} + (C_2 - C_1)\\
            \implies 2y + 16y + x^{4} &- 8x^{2} + C = 0\\
            (0, 1) \implies 2(1) + 16(1) + 0^{4} &- 8(0)^{2} + C = 0\\
            C &= -18\\
            \therefore 2y + 16y &+ x^{4} - 8x^{2} = 18
        \end{align}
    \end{example}
    \begin{homework}
        \begin{align}
            y' = \frac{dy}{dx} &= \frac{x^{2}}{y}\\
            y\,dy &= x^{2}\,dx\\
            \int y\,dy &= \int x^{2}\,dx\\
            \frac{1}{2}y^{2} &= \frac{1}{3}x^{3} + C\\
            y(x) &= \pm \sqrt{\frac{2}{3}x^{3} + C}
        \end{align}
    \end{homework}
    \chapter{23 January 2020}
    \section{Separable Equations (cont.)}
    \begin{example}
        From the textbook, 2.2, ex. 2.
        \begin{alignat}{2}
            \frac{dy}{dx}&=\frac{3x^2+4x+2}{2(y-1)} &\quad y(0) = -1
        \end{alignat}
        Given the above, determine the interval in which the solution exists.
        \begin{align}
            \int 2(y-1)\,dy&=\int (3x^{2} + 4x + 2)\,dx\\
            \implies y^2 - 2y + C_{1} &= x^3 + 2x^{2}+2x+C_2
        \end{align}
        The solution above is the \textbf{general implicit solution}. The constants, $C_{1}$ and $C_2$ can be combined into one constant, $C$, because they are independent.\\
        Next, use the initial value to solve for C
        \begin{alignat}{3}
            &&y(0) &= - 1\\
            &\implies & (-1)^{2} - 2(-1) &= 0^{3} + 2(0)^{2}+ 2(0) + C\\
            &\implies & C &= 3
        \end{alignat}
    \end{example}
    \np
    \begin{example*}[4.1 (cont.)]
        Then complete the square on the left hand side to get the \textbf{explicit~solution}.
        \begin{alignat}{3}
            && (y^{2} - 2y + 1) - 1 &= x^{3} + 2x^{2} + 2x + 3\\
            &\implies &(y - 1)^{2} &= x^{3} + 2x^{2} + 2x + 4\\
            &\implies & y - 1 &= \pm \sqrt{x^{3}  + 2x^{2} + 2x + 4}\\
            &\implies & y &= 1 \pm \sqrt{x^{3}  + 2x^{2} + 2x + 4}\\
            &\implies & y &= 1 - \sqrt{x^{3}  + 2x^{2} + 2x + 4}\\
            &\because & y(0) &= -1
        \end{alignat}
        \textbf{Note:} It is also possible to use the quadratic formula in order to convert this instance of an implicit into an explicit solution.\\
        \textbf{Observation}: Because the unique solution involves a square root, a function defined for $x \in [0, \infty)$, it is possible to reduce the original question to findinding when the radicand is non-negative.
        \begin{alignat}{3}
            &&x^{3} + 2 x^{2} + 2x + 4\ &= 0\\
            &&(x^{2} + 2)(x + 2) &= 0\\
            &\implies&x &\geq -2
        \end{alignat}
        The factor $x^{2} + 2$ will always be positive, so now the question is further reduced to when $x + 2$ will be non-negative, which is $x \in [-2, \infty)$.\\
        Therefore, the interval of which the solution exists is $(-2, \infty)$
    \end{example*}
    \begin{remark}[Solutions to Differential Equations]
        In \textbf{Example 4.1}, notice the final answer was an open interval, $(-2, \infty)$, rather than a half closed interval, $[-2, \infty)$, even if the solution would be defined if $x = -2$. The reason for this is that \textbf{solutions to differential equations must also be differentiable}.\\
        At point $x = -2$, the unique solution is defined, however, it is not differentiable as $\lim_{x \to -2^{-}}$ does not exist, because the function is not defined for $x < -2$.
    \end{remark}
    \np
    \section{Mathematical Modelling}
    \begin{example}[Modelling]
        Consider a pond fille with 10 million gallons of fresh water. A flow of 5 million gallons per year with water that is contaminated wiht a chemical enters the pond. There is also an outflow of this mixture on the order of 5 million gallons per year.\bigskip

        \noindent Let $\gamma(t)$ be the concentration of the fluid entering the pod at time $t$, and let $Q(t)$ be the quantity of chemicals in the pod at time $t$.\bigskip
        
        \noindent It is determined that
        \[\gamma(t) = 2 + \sin(2t)\ \text{g}\cdot\text{gal}^{-1}\]

        \noindent Find $Q(t)$ using the given information.\bigskip

        \noindent We can infer that $Q(0) = 0$ because the water starts off fresh at $t = 0$.\\
        We know that $\frac{dQ}{dt}$ is equal to the rate at which chemicals are entering minus the rate at which they leave, leading us to
        \[\frac{dQ}{dt} = I(t)\gamma(t) - \frac{O(t)}{V(t)}\big[Q(t)\big]\]
        Where $I(t)$ describes the rate at which the contaminated water enters, $O(t)$ describes the rate at which the water mixture leaves the pond, and $V(t)$ describes the total volume of the pond at any given time.\\
        In this case,
        \begin{alignat}{1}
            I(t) &= 5\times 10^{6}\ \text{gal}\,\text{year}^{-1}\\
            O(t) &= 5\times 10^{6}\ \text{gal}\,\text{year}^{-1}\\
            V(t) &= 10^{7}\ \text{gal}\\
        \end{alignat}
        Plugging in the values yields the following,
        \begin{alignat}{1}
            \frac{dQ}{dt} &= 5\times 10^{6}\gamma(t) - \frac{1}{2}Q(t)\\
        \end{alignat}
        Solving the linear differential equation,
        \begin{alignat}{3}
            &&\frac{dQ}{dt} + \frac{1}{2}Q(t) &=  5\times 10^{6}\gamma(t)\\
            &\implies&Q_{c}(t)&=5\times 10^{6}e^{-\frac{1}{2}t}\int e^{\frac{1}{2}t}(2 + \sin(2t))\,dt\\
            &\implies&Q_{c}(t)&=2\times 10^{7} + \frac{2\times 10^{7}}{17}\sin(2t)-\frac{4\times 10^{7}}{17}cos(2t) + Ce^{-\frac{1}{2}t}\\
            &&Q_{c}(0) &= 2\times 10^{7}-\frac{4\times 10^{7}}{17} + C = 0\\
            &\implies&C&=\frac{-3\cdot10^{8}}{17}
        \end{alignat}
        \begin{equation}    
            Q(t)=2\times 10^{7} + \frac{2\times 10^{7}}{17}\sin(2t)-\frac{4\times 10^{7}}{17}cos(2t) - \frac{3\cdot10^{8}}{17}e^{-\frac{1}{2}t}
        \end{equation}
    \end{example}
    \begin{remark}[Behavior of Example 4.2]
        When graphing this equation, it can be seen that in the long term the equation becomes periodic despite beginning with an irregular pattern. This is due to the fact that the term $- \frac{3\cdot10^{8}}{17}e^{-\frac{1}{2}t}$ is able to affect the behavior in the short term, however, it is decaying exponentially and tends towards $0$. The $\sin$ and $\cos$ functions are periodic which cause the sinusoidial shape of the graph as $t \to \infty$.
    \end{remark}
    \chapter{28 January 2020}
    \section{Mathematical Modelling (cont.)}
    \begin{example}
        Example 2.3.1 from the textbook.
        \begin{enumerate}
            \item Find the amount of salt in the tank at a time $t$ ($Q(t)$).\\
            Inference: $Q(0) = Q_{0}$
            \begin{alignat}{3}
                &&\frac{dQ}{dt}&=\frac{1}{4}r - \frac{rQ}{100}\\
                &\implies&Q' + \frac{r}{100}Q&=\frac{1}{4}r\\
                &\implies&Q_{c}&=\exp\bbbp{-\frac{r}{100}t}\int\BBp{\exp\bbbp{\frac{r}{100}t}\frac{1}{4}r\,}dt\\
                &&&=\frac{r}{4}\exp\bbbp{\frac{-r}{100}t}\BBp{\frac{100}{r}\exp\bbbp{\frac{r}{100}t}+C}\\
                &&&=25 + \frac{r}{4}\exp\bbbp{-\frac{r}{100}t}C\\
                &&&=25 + C\exp\bbbp{-\frac{r}{100}t}\\
                &&Q(0)&=Q_{0}\\
                &\implies&C&=(Q_{0} - 25)\exp\bbbp{-\frac{r}{100}t}\\
                &\implies&Q(t)&=25 + (Q_{0} - 25)\exp\bbbp{-\frac{r}{100}t}
            \end{alignat}
            \item Find the limiting amount, $Q_{l}$, after a long time.
            \begin{equation}
                \lim_{t\to\infty}(Q_{c}(t)) = Q_{c} = 25
            \end{equation}
        \end{enumerate}
    \end{example}
    \begin{remark}[Regarding Example 5.1]
        Notice that no matter the amount of salt that the system starts with, it will always tend towards 25 lbs of salt in the tank.
    \end{remark}
    \section{Exact Differential Equations}
    \begin{definition}[Exact Differential Equations]
        A differential equation is exact iff
        \begin{equation}
            \frac{\partial M(x,y)}{\partial y} = \frac{\partial N(x,y)}{\partial x} \Leftrightarrow N(x, y)y' + M(x, y) = 0
        \end{equation}
        \begin{equation}
            M(x, y)\,dx + N(x, y)\,dy = 0
        \end{equation}
    \end{definition}
    Given $\psi(x, y)$, parameterize by using $\delta(t) = \psi(f_{1}(t), f_{2}(t))$.
    \begin{alignat}{1}
        \frac{d\psi(x, y)}{dt} &= \frac{d\delta}{dt}\\
        &= \frac{\partial \psi(x, y)}{\partial x}\frac{df_{1}}{dt} + \frac{\partial \psi(x, y)}{\partial y}\frac{df_{2}}{dt}
    \end{alignat}
    \begin{example}
        \begin{alignat}{1}
            \psi(x, y) &= x^{2}y + xy\\
            f_{1}(t) = t&,\quad f_{2}(t) = t^{2}\\
            \delta(t) &= \psi(f_{1}, f_{2})\\
            &= t^{2}t^{2}+t t^{2}\\
            \delta'(t) &= 4t^{3} + 3t^{2}\label{5219}\\
            \frac{\partial \psi(x, y)}{\partial x}\cdot 1 &+ \frac{\partial \psi(x, y)}{\partial y}\cdot2t\\
            &= (2f_{1}f_{2} + f_{2})\cdot 1 + (f_{1}^{2} + f_{1})\cdot 2ty\\
            &= 4t^{3} + 3t^{2}\label{5222}
        \end{alignat}
        Notice how \textbf{Equation \ref{5219}} and \textbf{Equation \ref{5222}} are the same, but derived via different methods.
    \end{example}
    \begin{example}
        \begin{enumerate}
            \item $y' = \frac{\frac{1}{y}}{x}$ is an exact differential equation.\\
            Let $M(x, y) = \frac{1}{x}$, and $N(x, y) = y$.
            \[\frac{\partial M(x,y)}{\partial y} = \frac{\partial \frac{1}{x}}{\partial y} = 0\]
            \[\frac{\partial N(x,y)}{\partial x} = \frac{\partial y}{\partial x} = 0\]
            Because both partial derivatives are equal, they are exact.
            \item $y' = x$ is exact.
            \item $y' = \frac{xy}{x + y} \iff (x + y)\,dy + xy\,dx = 0$ is exact.
            \item $y' = \frac{xy + x}{\frac{1}{2}x^2 + y}$ is exact.
        \end{enumerate}
    \end{example}
    \begin{btheorem}[Exactness]
        The equation \[
            M(x, y)\,dx + N(x, y)\,dy = 0
        \] is exact if, and only if, $\exists\,\psi(x, y)$ s.t.
        \[
            \frac{\partial \psi(x,y)}{\partial x} = M(x, y)
            \]\[
            \frac{\partial \psi(x,y)}{\partial y} = N(x, y)
        \]
    \end{btheorem}
    \begin{remark}[Relationship]
        Exact differential equations are a superset of the separable differential equations, i.e. all separable differential equations are exact differential equations.
    \end{remark}
    \chapter{30 January 2020}
    \section{Exact Differential Equations (cont.)}
    \begin{example}
        Solve
        \begin{equation}
            \label{Exact1}
            (y\cos x + 2xe^{y}) + (\sin x + x^{2} + x^{2}e^{y} - 1)y' = 0
        \end{equation}
        Checking if \textbf{Equation \ref{Exact1}} is exact,
        \begin{alignat}{2}
            \frac{\partial M(x, y)}{\partial y} &= \frac{\partial (y\cos x + 2xe^y)}{\partial y} &= \cos x + 2xe^y\\
            \frac{\partial N(x, y)}{\partial x} &= \frac{\partial (\sin x + x^{2}e^{y} - 1)}{\partial y} &= \cos x + 2xe^y
        \end{alignat}
        From the above, this is an exact differential equation.
        \begin{alignat}{1}
            \psi(x, y) &= \int M(x, y)\,dx + h(y)\\
            &= \int (y\cos x + 2xe^{y})\,dx + h(y)\\
            &= h(y) + y\sin x+ x^{2}e^{y} + C\\
            &= h(y) + y\sin x + x^{2}e^{y}
         \end{alignat}
         Notice that the constant can be neglected as it can be contained in $h(y)$. Now solving for $h(y)$,
         \begin{alignat}{3}
            &&\psi_{y}(x, y) &= N(x, y)\\
            &\implies&\frac{dh}{dy} + \frac{\partial(y\sin x + e^{y}x^{2})}{\partial y}&=\sin x + x^{2}e^{y} - 1\\
            &&\frac{dh}{dy} + \sin x + x^{2}e^{y}&=\sin x + x^{2}e^{y} - 1\\
            &&\frac{dh}{dy}&= -1\\
            &&h&=-y + C
         \end{alignat}
         Then,
         \begin{equation}
             \psi(x, y) = y\sin x + x^{2}e^{y} - y + C
         \end{equation}
         Finally, $y(x)$ is given by the implicit expression
         \begin{equation}
             y\sin x + x^{2}e^{y} - y = C
         \end{equation}
    \end{example}
    \begin{example}
        Solve
        \begin{equation}
            \label{Exact2}
            (3xy + y^{2}) + (x^{2} + xy)y' = 0
        \end{equation}
        Checking if the equation is exact,
        \begin{alignat}{1}
            \frac{\partial (3xy + y^{2})}{\partial y} &= 3x + 2y\\
            \frac{\partial (x^{2} + xy)}{\partial x} &= 2x + y
        \end{alignat}
        Notice that they are not equal; however,
        \begin{equation}
            \mu(x)(3xy + y^{2}) + \mu(x)(x^{2} + xy)y' = 0
        \end{equation}
        is an exact differential equation if
        \begin{equation}
            -\frac{N_{x}(x, y) + M_{y})x, y}{N(x, y)}
        \end{equation}
        is a function dependent only on $x$. However, $\forall M(x, y), N(x, y) \nexists \mu(x)$. $\mu(x)$ can be found by solving the differential equation,
        \begin{alignat}{1}
            \frac{d\mu}{dx} &= \frac{-N_{x}(x, y) + M_{y}(x, y)}{N(x, y)}\mu\\
            \mu(x) &= \exp\bbbp{\int\frac{N_{x} - M_{y}}{N}\,dx}
        \end{alignat}
        In this problem,
        \begin{equation}
            \frac{M_{y} - N_{x}}{N} = \frac{(3x + 2y) - (2x + y)}{x^2 + xy} = \frac{1}{x}
        \end{equation}
        \begin{equation}
            \mu(x) = \exp\bbbp{\int\frac{dx}{x}} = x + C
        \end{equation}
        Multiplying \textbf{Equation \ref{Exact2}} by $\mu(x)$ yields,
        \begin{equation}
            (3x^{2}y + y^{2}x) + (x^{3} + x^{2}y)y' = 0
        \end{equation}
        Checking if the equation is exact yields the following,
        \begin{alignat}{1}
            \frac{\partial 3x^{2}y + xy^{2}}{\partial y} &= 3x^{2} + 2xy\\
            \frac{\partial x^{3} + x^{2}y}{\partial x} &= 3x^{2} + 2xy
        \end{alignat}
        and is therefore exact.
        \begin{alignat}{1}
            \psi(x, y) &= \int(3x^{2}y + xy^{2})\,dx + h(y)\\
            &= x^{3}y + \frac{1}{2}x^{2}y^{2}+h(y)\\
            \frac{\partial\psi(x, y)}{\partial y} &= x^{3} + x^{2}y + \frac{dh}{dy}\\
            &= N(x, y)\\
            \frac{dh}{dy} &= x^{3} + x^{2}y = x^{3} + x^{2}y\label{6232}\\
            h &= 0
        \end{alignat}
        Finally, $y(x)$ can be expressed as,
        \begin{equation}
            x^{3}y + \frac{1}{2}x^{2}y^{2} = C
        \end{equation}
    \end{example}
    \begin{method}[Solving Exact Differential Equations]
        \begin{enumerate}
            \item Step 1: Determine if the equation is exact
            \begin{equation}
                \frac{\partial M(x, y)}{\partial y} = \frac{\partial N(x, y)}{\partial x}
            \end{equation}
            \item Step 2: Find $\psi(x, y)$ such that $\psi_{x}(x, y) = M(x, y)$, and $\psi_{y}(x, y) = N(x, y)$. Generally,
            \begin{equation}
                    \psi(x, y) = \int M(x, y)\,dx + h(y)
            \end{equation}
            this works because
            \begin{alignat}{1}
                \frac{\partial \psi(x, y)}{\partial x} &= \frac{\partial \int M(x, y)\,dx}{\partial x} + \frac{\partial h(y)}{\partial x}\\
                &= M(x, y) + 0 
            \end{alignat}
            Then find $h(y)$ such that $\psi_{y}(x, y) = N(x, y)$.
        \end{enumerate}
    \end{method}
    \begin{remark}
        Note in step 2 of \textbf{Method 6.1}
        \begin{equation}
            \psi(x, y) = \int M(x, y)\,dx + h(y)
        \end{equation}
        can also be defined as
        \begin{alignat}{1}
            \psi(x, y) &= \int N(x, y)\,dy + h(x)\\
            \frac{\partial \psi(x, y)}{\partial y} = \psi_{y}(x, y) &= \frac{\partial \int N(x, y)\,dy}{\partial y} + \frac{\partial h(x)}{\partial y}\\
            &= N(x, y) + 0
        \end{alignat}
    \end{remark}
    \begin{remark}
        $y(x)$ is a solution for $M(x, y)\,dx + N(x, y)\,dy = 0$ iff $\psi(x, y(x)) = c$.
        Consider the following,
        \[
            \frac{d\psi(f_{1}, f_{2})}{dt} = \frac{\partial \psi(x, y)}{\partial x}\frac{df_{1}}{dt} + \frac{\partial \psi(x, y)}{\partial y}\frac{df_{2}}{dt}
        \]
        we can replace $t$ with $x$, let $f_{1} \equiv x$ and $f_{2} \equiv y(x)$, then
        \begin{alignat}{1}
            \frac{d\psi(f_{1}(x), f_{2}(x))}{dx} &= \frac{\partial \psi(x, y)}{\partial x}\frac{df_{1}}{dx} + \frac{\partial \psi(x, y)}{\partial y}\frac{df_{2}}{dx}\\
            &= \frac{\partial \psi(x, y)}{\partial x} + \frac{\partial \psi(x, y)}{\partial y}\frac{dy}{dx}
        \end{alignat}
        finally,
        \[
            N(x, y)\frac{dy}{dx} = \frac{\partial \psi(x, y)}{\partial y} \frac{dy}{dx} = \frac{d\psi(x, y(x))}{dx} - \frac{\partial \psi(x, y)}{\partial x}
        \]
    \end{remark}
    \begin{remark}
        Notice in \textbf{Equation \ref{6232}} has 3 variables: $h, x, y$; however, the terms with $x$ cancel, leaving just $h$ and $y$. This occurs due to the equation being exact.
    \end{remark}
    \chapter{4 February 2020}
    Recall in the last lecture:
    \begin{alignat}{1}
        M_{y}(x, y) &= N_{x}(x, y)\\
        \implies \exists\,\psi(x, y(x)):&= \psi_{x}=M(x,y); \psi_{y}=N(x, y)\\
        \psi(x) = \psi(x, y) &\equiv C
    \end{alignat}
    For example,
    \begin{alignat}{1}
        \psi(x, y) &= x + y\\
        x + y(x) &= C\\
        y &= C - x
    \end{alignat}
    And if $\frac{M_{y}(x, y) - N_{x}(x, y)}{N(x, y)}$ depends only on $x$, then $\exists\,\mu(x): \frac{d\mu}{dx} = \frac{M_{y}(x, y) - N_{x}(x, y)}{N(x, y)}\mu$. Thus, the differential equation $\mu M + \mu Ny' = 0$ is an exact differential equation.
    \section{Uniqueness and Exactness}
    \begin{btheorem}[Uniqueness of Linear Differential Equations]
        Consider the linear first order differential equation,
        \begin{equation}
            y' + p(t)y = g(t);\quad y(t_{0}) = y_{0}
        \end{equation}
        such that in some open interval, $I = (\alpha; \beta)$, $p(t)$ and $g(t)$ are continuous and $t_{0} \in I$.\\
        Then,
        \begin{equation}
            \exists!\,y(t): y(t_{0}) = y_{0} \wedge y' + p(t)y = g(t)
        \end{equation}
    \end{btheorem}
    \begin{btheorem}[Uniqueness of Non-linear Differential Equations]
        Consider the following,
        \begin{equation} 
            y' = f(t, y) \wedge y(t_{0}) = y_{0}
        \end{equation}
        such that $f(t, y)$ and $\frac{\partial f(t, y)}{\partial y}$ are continuous over the domains $t \in (\alpha; \beta)$, and $y \in (\gamma; \delta)$.\\
        Then, $h > 0, I = (t_{0} - h, t_{0} + h): \exists t_{0} \in I, y(t_{0}) = y_{0}$.
    \end{btheorem}
    \begin{example}
        \begin{equation}
            ty' + 2y = 4t^{2};\quad y(1) = 2
        \end{equation}
        Use \textbf{Theorem 7.1} to find an interval $\exists!y(t)$.
        \begin{alignat}{1}
            y' + \frac{2}{t}y &= 4t\\
            p(t) = \frac{2}{t}&,\quad g(t) = 4t
        \end{alignat}
        In the interval $I := (\alpha, \beta)$, $\exists t \in I: p(t), g(t) \implies \exists! y(t)$
        \begin{enumerate}
            \item $\forall\ t \in (-\infty, 0)\cup(0,\infty), p(t)$
            \item $\forall\ t \in (-\infty, \infty), g(t)$
            \item $1 \in (\alpha,\beta)$
            \item Therefore, $\alpha = 0, \beta = \infty \implies I = (0, \infty) = \RR^{+}$
        \end{enumerate}
    \end{example}
    % TODO: Comeback and add the other example
    \chapter{6 February 2020}
    \section{First Order Differential Equation Review}
    Topics covered in First Order Differential Equations.
    \begin{itemize}
        \item $y' = f(x, y)$\quad$y(x_{0}) = y_{0}$
        \item First Order LDE, $y' + p(t)y = g(t)$
        \item Separable, $y' = \frac{M(x, y)}{N(x, y)}$
        \item Exact, $M(x, y) + N(x, y)y' = 0$; $M_{y}(x, y) = N_{x}(x, y)$
        \item Uniqueness and Existance Theorems
        \item Modelling
    \end{itemize}
    \section{Second Order Differential Equations}
    \begin{definition}[Second Order Differential Equations]
        The general form of a \textbf{second order differential equation} (SODE) is
        \begin{equation}
            y'' = f(x, y, y');\quad y(x_{0}) = y_{0};\quad y'(x_{0}) = y_{1}
        \end{equation}
    \end{definition}
    \np
    \begin{example}
        The following are SODEs,
        \begin{alignat}{1}
            y'' &= 1\\
            y'' &= 1 + y'\\
            y'' &= \frac{x}{t}
        \end{alignat}
        An example of a SODE IVP,
        \begin{equation}
            y'' = x + y + y';\quad y(0) = 1;\quad y'(0) = -3
        \end{equation}
    \end{example}
    \begin{definition}[Second Order Linear Differential Equations]
        A \textbf{second order linear differential equation} (SOLDE) has the general form
        \begin{equation}
            y'' + p(t)y' + q(t)y = g(t)
        \end{equation}
        where $p(t)$, $q(t)$, $g(t)$ are continuous over some interval $I$.
    \end{definition}
    \begin{btheorem}[SOLDE Uniqueness Theorem]
        If $p(t), q(t), g(t)$ are continuous in some interval $I: (\alpha, \beta)$\\
        Then, for any $t_{0} \in I$, the IVP defined by
        \begin{equation}
            y'' + p(t)y' + q(t)y = g(t),\quad y(x_{0}) = y_{0},\quad y'(x_{0}) = y_{1}
        \end{equation}
        has a unique solution.
    \end{btheorem}
    \begin{definition}[Cases of SOLDEs]
        \textbf{Homogeneous SOLDEs} (HSOLDE) are of the following form
        \begin{equation}
            y'' + p(t)y' + q(t)y = 0
        \end{equation}
        If a Homogeneous SODE is defined where $p(t)$, and $q(t)$ are constants, it is considered as a \textbf{homogeneous SOLDE with Constant Coefficients} (CHSOLDE).
    \end{definition}
    \np
    \section{Homogeneous Second Order Linear Differential Equations with Constant Coefficients}
    \begin{example}[CHSOLDE]
        Find the general solution of
        \begin{equation}
            \label{CHSOLDE1}
            L[y] = y'' + 5y' + 6y = 0
        \end{equation}
        Consider the following quadratic (characteristic function, or characteristic polynomial).
        \begin{equation}
            f(r) = r^{2} + 5r + 6 = 0
        \end{equation}
        There are 2 different roots to the characteristic function,
        \begin{equation}
            r_{1} = -3;\quad r_{2} = -2
        \end{equation}
        Now consider the equations,
        \begin{equation}
            y_{1}(t) = e^{r_{1}t} = e^{-2t}
        \end{equation}
        \begin{equation}
            y_{2}(t) = e^{r_{1}t} = e^{-3t}
        \end{equation}
        Then, $y_{1}(t)$ and $y_{2}(t)$ are solutions of \textbf{Equation \ref{CHSOLDE1}}.\\
        \textbf{Proof:}
        \begin{alignat}{1}
            &y_{1}'(t) = -3e^{-3t};\quad y_{1}'' = 9e^{-3t}\\
            L[y_{1}] &= 9e^{-3t} + 5(-3)e^{-3t} + 6e^{-3t} = 0 \\
            0&= (9 - 15 + 6)e^{-3t}
        \end{alignat}
        Therefore, the general solution to \textbf{Equation \ref{CHSOLDE1}}
        \begin{alignat}{1}
            y_{c} = C_{1}e^{-3t} + C_{2}e^{-2t}
        \end{alignat}
        where $C_1$ and $C_2$ are constants.
    \end{example}
    \np
    \begin{example}
        \begin{equation}
            L[y] = y'' + ay' + by = 0
        \end{equation}
        \begin{equation}
            f(r) = r^{2} + ar + b = 0
        \end{equation}
        Suppose that $r_{0}$ is a root of $f(r) = 0$\\
        Consider \begin{alignat}{1}
            y_{0}(t) &= e^{r_{0}t}\\
            y_{0}'(t) &= r_{0}e^{r_{0}t}\\
            y_{0}''(t) &= r_{0}^{2}e^{r_{0}t}\\
            \implies L(y_{0}) &= r_{0}^{2}e^{r_{0}t} + ar_{0}e^{r_{0}t} + be^{r_{0}t}\\
            &=e^{r_{0}t}(r_{0}^{2} + ar_{0} + b)
        \end{alignat}
        Things to consider, what if $r_{0} \in \CC$ or $r_{0} = r_{1}$?
    \end{example}
    \begin{example}[CHSOLDE IVP]
        Find the solution of the CHSOLDE IVP,
        \begin{equation}
            L[y] = y'' + 5y' + 6y = 0;\quad y(0) = 2;\quad y'(0) = 3
        \end{equation}
        \begin{enumerate}
            \item Find the general solution
            \begin{equation}
                y_{c}(t) = C_{1}y_{1} + C_{2}y_{2} \implies y_{c}(t) = C_{1}e^{-3t} + C_{2}e^{-2t}
            \end{equation}
            \item Find the particular values of $C_1$ and $C_2$ such that $C_{1}y_{1}(0) + C_{2}y_{2}(0) = 2$ and $(C_{1}y_{1}(0) + C_{2}y_{2}(0))' = 3$.
            \begin{equation}
                \begin{cases}
                    C_{1}e^{-3(0)} + C_{2}e^{-2(0)} = 2\\
                    -3C_{1}e^{-3(0)} + -2C_{2}e^{-2(0)} = 3\\
                \end{cases}
            \end{equation}
            Solving the linear combination yields $C_{1} = 7$, $C_{2} = 9$.
            Then, the solution to this IVP is
            \begin{equation}
                y(t) = -7e^{-3t} + 9 e^{-2t}
            \end{equation}
        \end{enumerate}
    \end{example}
    \chapter{11 February 2020}
    \section{Second Order Linear Differential Equations}
    \begin{btheorem}[Principle of Superposition]
        Suppose that $y_{1}$ and $y_{2}$ are solutions of
        \begin{equation}
            L[y]= y'' + p(t)y' + q(t)y= 0
        \end{equation}
        Then, $C_{1}y_{1} + C_{2}y_{2}$ is another solution for $L[y] = 0$ where $C_{1}$ and $C_{2}$ are constants.
        ($C_{1}y_{1} + C_{2}y_{2}$ is the liear combination of $y_{1}$ and $y_{2}$)
    \end{btheorem}
    \begin{bproof}[Principle of Superposition]
        Show that
        \begin{equation}
            L[C_{1}y_{1} + C_{2}y_{2}] = 0
        \end{equation}
        \begin{alignat}{1}
            &L[C_{1}y_{1} + C_{2}y_{2}]\\
            &= (C_{1}y_{1} + C_{2}y_{2})'' + p(t)(C_{1}y_{1} + C_{2}y_{2})' + q(t)(C_{1}y_{1} + C_{2}y_{2})\\
            &=C_{1}y_{1}'' + C_{2}y_{2}'' + p(t)C_{1}y_{1}' + p(t)C_{2}y_{2}' + q(t)C_{1}y_{1} + q(t)C_{2}y_{2}\\
            &= (C_{1}y_{1}'' + p(t)C_{1}y_{1}' + q(t)C_{1}y_{1}) + (C_{2}y_{2}'' + p(t)C_{2}y_{2}' + q(t)C_{2}y_{2})\\
            &= C_{1}L[y_{1}] + C_{2}L[y_{2}] = 0
        \end{alignat}
        From the above, $C_{1}L[y_{1}] = 0$ and $C_{2}L[y_{2}] = 0$, therefore
        \begin{equation}
            L[C_{1}y_{1} + C_{2}y_{2}] = 0
        \end{equation}
    \end{bproof}
    \np
    \begin{btheorem}[Existance and Uniqueness Theorem]
        Given
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = g(t);\quad y(t_{0}) = z_{0};\quad y'(t_{0}) = z_{1}
        \end{equation}
        suppose $t_{0}\in I$.\\Then, this IVP has exactly 1 solution. Moreover, this solution will be defined throughout the interval.
    \end{btheorem}
    \begin{example}[Application of Existance and Uniqueness Theorem]
        Find the longest interval in which the solution of the IVP is certain to exist.
        \begin{equation}
            (t^{2}-3t)y'' + ty' - (t + 3) y = 0;\quad y(1) = 2;\quad y(1) = 1
        \end{equation}
        The equation is equivalent to
        \begin{equation}
            L[y] = y'' + \frac{t}{t^{2} - 3t}y' - \frac{t + 3}{{t^{2} - 3t}}y = 0
        \end{equation}
        \begin{enumerate}
            \item $\forall\ t \in (-\infty, \infty), \lim_{a\to t}(g(a))$
            \item $\forall\ t \in (-\infty, 0)\cup(0, 3)\cup(3,\infty), \lim_{a\to t}(q(a))$
            \item $\forall\ t \in (-\infty, 3)\cup(3,\infty), \lim_{a\to t}(p(a))$
        \end{enumerate}
        From the above,
        \begin{equation}
            I = (0, 3)
        \end{equation}
    \end{example}
    \begin{example}
        Find the unique solution of the IVP given by
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t) y = 0;\quad y(t_{0}) = 0;\quad y'(t_{0}) = 0
        \end{equation}
        where $p(t)$ and $q(t)$ are continuous for $t \in (-\infty, \infty)$.\\
        The solution is
        \begin{equation}
            y(t) = 0
        \end{equation}
        and because of the uniqueness theorem, this is the only answer.
    \end{example}
    \np
    \section{Linear Algebra with 2 Unknowns Detour}
    \begin{definition}
        General form of a linear system with 2 Unknowns
        \begin{equation}
            \begin{cases}
                a_{1}x + b_{1}y = c_{1}\\
                a_{2}x + b_{2}y = c_{2}
            \end{cases}
        \end{equation}
        where $x$ and $y$ are the two unknowns.
        The linear combination above can be rewritten as
        \begin{equation}
            \begin{pmatrix}
                a_{1} & b_{1}\\
                a_{2} & b_{2}
            \end{pmatrix}
            \begin{pmatrix}
                x\\ y
            \end{pmatrix}
            =
            \begin{pmatrix}
                c_{1}\\ c_{2}
            \end{pmatrix}
        \end{equation}
    \end{definition}
    \begin{definition}[Matricies]
        A $n \times m$ \textbf{matrix} is a $n \times m$ table filled with numbers or functions. They are written with parenthesis or brackets around the numbers, such as
        \begin{equation}
            \begin{pmatrix}
                0 & 1\\
                -1 & 2
            \end{pmatrix}=
            \begin{bmatrix}
                0 & 1\\
                -1 & 2
            \end{bmatrix}
        \end{equation}
        When $n = m$, the matrix is considered to be a \textbf{square matrix}.
    \end{definition}
    \np
    \begin{definition}[Determinant]
        An import concept involved with square matricies is the determinant, in the case of
        \begin{equation}
            \det(A) = 
        \det\begin{pmatrix}
            a_{1} & b_{1}\\
            a_{2} & b_{2}
        \end{pmatrix} = ad - bc
        \end{equation}
    \end{definition}
    \begin{btheorem}
        The solution to
        \begin{equation}
            \begin{cases}
                a_{1}x + b_{1}y = c_{1}\\
                a_{2}x + b_{2}y = c_{2}
            \end{cases}
        \end{equation}
        is given by
        \begin{equation}
            x = \frac{\begin{vmatrix}
                c_{1} & b_{1}\\
                c_{2} & b_{2}
            \end{vmatrix}}{\begin{vmatrix}
                a_{1} & b_{1}\\
                a_{2} & b_{2}
            \end{vmatrix}};\quad
            y = \frac{\begin{vmatrix}
                a_{1} & c_{1}\\
                a_{2} & c_{2}
            \end{vmatrix}}{\begin{vmatrix}
                a_{1} & b_{1}\\
                a_{2} & b_{2}
            \end{vmatrix}}
        \end{equation}
        where $\begin{vmatrix}a_{1} & b_{1}\\a_{2} & b_{2}\end{vmatrix} \neq 0$. No other solution exists.
    \end{btheorem}
    \section{Wronskian}
    \begin{definition}[Wronskian]
        For two differentiable functions $y_{1}(t)$ and $y_{2}(t)$ are solutions to $L[y]= 0$, the \textbf{Wronskian} of $y_{1}$ and $y_{2}$ is defined by
        \begin{equation}
            W[y_{1}, y_{2}] = \begin{vmatrix}
                y_{1} & y_{2}\\
                y_{1}' & y_{2}'
            \end{vmatrix}
        \end{equation}
    \end{definition}
    \np
    \section{Miscellaneous Definitions}
    Additional notes that were either not covered or were missed from previous lectures.
    \begin{definition}[Differential Operator]
        Let $p$ and $q$ are continuous over the open interval $I$, where $t\in(\alpha, \beta)$, where $\alpha = -\infty$ or $\beta = \infty$ are included. Then for any function $\phi$ that is twice differentiable on $I$.
        The \textbf{differential operator} is defined by
        \begin{equation}
            L[\phi] = \phi'' + p\phi' + q\phi
        \end{equation}
        Note that result of the operator is a function itself, so the value of $L[\phi]$ at point $t$ is
        \begin{equation}
            L[\phi] = \phi''(t) + p(t)\phi'(t) + q(t)\phi(t)
        \end{equation}
    \end{definition}
    \chapter{13 February 2020}
    \section{Applications of the Wronskian}
    \begin{corollary}
        Recall in the last lecture, \textbf{Theorem 9.3}.
        Let
        \begin{equation}
            A = \begin{pmatrix}
                a_{1} & b_{1}\\
                a_{2} & b_{2}
            \end{pmatrix}
        \end{equation}
        If $|A| = 0$, then for \textbf{some} values of $c_{1}$ and $c_{2}$ the linear system
        \begin{equation}
            \begin{cases}
                a_{1}x + b_{1}y = c_{1}&\\
                a_{2}x + b_{2}y = c_{2}&\\
            \end{cases}
        \end{equation}
        does not have a solution (inconsistent).
    \end{corollary}
    \np
    \begin{btheorem}
        Assume that $y_{1}$ and $y_{2}$ are solutions to
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = 0
        \end{equation}
        where $p$ and $q$ are continuous, and $t_{0}$ is a fixed point.\\
        Then, $\forall z_{0} \wedge \forall z_{1}$, it is possible to find $c_{1}$ and $c_{2}$ such that
        \begin{equation}
            y(t) = c_{1}y_{1}(t) + c_{2}y_{2}(t)
        \end{equation}
        satisfies the IVP
        \begin{equation}
            L[y],\quad  y(t_{0}) = z_{0},\quad y'(t_{0}) = z_{1}
        \end{equation}
        if and only if
        \begin{equation}
            W[y_{1}, y_{2}](t_{0}) \neq 0
        \end{equation}
    \end{btheorem}
    \begin{bproof}
        Suppose that $\forall z_{0}, z_{1} \implies \exists\, C_{1}, C_{2}$ such that
        \begin{equation}
            \begin{cases}
                C_{1}y_{1}(t_{0}) + C_{2}y_{2(t_{0})} = z_{0}&\\
                C_{1}y_{1}'(t_{0}) + C_{2}y_{2}'(t_{0}) = z_{1}&
            \end{cases}
        \end{equation}
        then, $\exists!\,C_{1}, C_{2}$ iff $W[y_{1}, y_{2}](t_{0}) \neq 0$
    \end{bproof}
    \begin{btheorem}
        Suppose that $y_{1}$ and $y_{2}$ are solutions to
        \begin{equation}
            L[y] = 0
        \end{equation}
        Then, the family of solutions
        \begin{equation}
            y=C_{1}y_{1} + C_{2}y_{2}
        \end{equation}
        includes all solutions of $L[y] = 0$ iff $\exists t_{0} \implies W[y_{1}, y_{2}](t_{0}) \neq 0$
    \end{btheorem}
    \np
    \begin{example}[Application of 10.2]
        The solutions to
        \begin{equation}
            y'' - 5y' + 6y = 0
        \end{equation}
        are
        \begin{equation}
            y_{1} = e^{2t},\quad y_{2} = e^{3t}
        \end{equation}
        \begin{equation}
            y = C_{1}e^{2t} + C_{2}e^{3t}
        \end{equation}
        Calculating the Wronskian
        \begin{alignat}{1}
            W[y_{1}, y_{2}] &= \begin{vmatrix}
                e^{2t} & e^{3t}\\
                2e^{2t} & 3e^{3t}
            \end{vmatrix}\\
            &= e^{5t}
        \end{alignat}
        \begin{equation}
            e^{5t} \neq 0
        \end{equation}
        Therefore, there does not exist other solutions to this CHSOLDE.
    \end{example}
    \begin{btheorem}[Abel's Theorem]
        If $y_{1}, y_{2}$ are solutions to a SOLDE,
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = 0
        \end{equation}
        where $p, t$ are continuous over an open interval, $I$, then the Wronskian at point $t$ is given by Abel's Formula,
        \begin{equation}
            W[y_{1}, y_{2}](t) = c\exp\bbbp{-\int p(t)\,dt}
        \end{equation}
        where $c$ is some arbitrary constant dependent on $y_{1}, y_{2}$, but not on $t$.
        \begin{alignat}{1}
            \forall t\in I, W[y_{1}, y_{2}](t) &\equiv 0 \iff c = 0\\
            \forall t\in I, W[y_{1}, y_{2}](t) &\nequiv 0 \iff c \neq 0
        \end{alignat}
    \end{btheorem}
    \np
    \begin{example}
        Suppose that
        \begin{equation}
            y_{1}(t) = e^{r_{1}t},\quad y_{2}(t) = e^{r_{2}t}
        \end{equation}
        are solutions of
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = 0
        \end{equation}
        Show that if $r_{1} \neq r_{2}$, then $C_{1}y_{1} + C_{2}y_{2}$ includes all solutions of $L[y] = 0$.
        \begin{alignat}{1}
            W[e^{r_{1}t}, e^{r_{2}t}] &= \begin{vmatrix}
                e^{r_{1}t} & e^{r_{2}t}\\
                r_{1}e^{r_{1}t} & r_{2}e^{r_{2}t}
            \end{vmatrix}\\
            &= (r_{2} - r_{1})e^{(r_{1} + r_{2})t}\\
            &\neq 0
        \end{alignat}
    \end{example}
    \begin{definition}[Fundamental Set of Solutions]
        If $y_{1}$ and $y_{2}$ are solutions of
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = 0
        \end{equation}
        such that $C_{1}y_{1} + C_{2}y_{2}$ includes all possible solutions of $L[y] = 0$, then $y_{1}$ and $y_{2}$ form a \textbf{fundamental set of solutions} (FSS).\\
        Alternatively, if and only if
        \begin{equation}
            W[y_{1}, y_{2}] \neq 0
        \end{equation}
        then there exists fundamental set containing $y_{1}$ and $y_{2}$.
    \end{definition}
    \begin{example}
        Show that $y_{1}(t) = t^{\frac{1}{2}}$, $y_{2}(t) = t^{-1}$ form a FSS of
        \begin{equation}
            2t^{2}y'' + 3ty'-y=0,\quad t > 0
        \end{equation}
        \begin{enumerate}
            \item Ensure they are solutions of $L[y] = 0$\\
            i.e. $L[t^{\frac{1}{2}}] = 0$, $L[t^{-1}] = 0$
            \begin{alignat}{1}
                L[t^{\frac{1}{2}}] &= 2t^{2}(-\frac{1}{4})t^{-\frac{3}{4}}+3t(\frac{1}{2})t^{-\frac{1}{2}} + t^{\frac{1}{2}}\\
                &= -\frac{1}{2}t^{\frac{1}{2}} + \frac{3}{2}t^{\frac{1}{2}}-t^{\frac{1}{2}}\\
                &\equiv 0
            \end{alignat}
            \begin{alignat}{1}
                L[t^{-1}] &= (2t^{2})(2t^{-3}) + 3t(-1)t^{-2}-t^{-1}\\
                &= 4t^{-1} - 3t^{-1} - t^{-1}\\
                &\equiv 0
            \end{alignat}
            \item Ensure that the Wronskian is not constantly equal to 0
            \begin{alignat}{1}
                W[t^{\frac{1}{2}}, t^{-1}] &= \begin{vmatrix}
                    t^{\frac{1}{2}} & t^{-1}\\
                    \frac{1}{2}t^{-\frac{1}{2}} & -t^{-1}
                \end{vmatrix}\\
                &= -t^{-\frac{1}{2}} - -\frac{1}{2}t^{-\frac{3}{2}}\\
                &\nequiv 0
            \end{alignat}
        \end{enumerate}
        Then,
        \begin{equation}
            L[y] = y'' + ay' + by = 0;\quad f(r) = r^{2} + ar + b = 0
        \end{equation}
        has only one solution of degree 2.
        \begin{equation}
            r_{1,2} = \frac{-a\pm\sqrt{a^{2} - 4b}}{2},\quad r_{1} = r_{2} \iff \sqrt{a^{2} - 4b} \equiv 0
        \end{equation}
    \end{example}
    \begin{example}
        \begin{enumerate}
            \item If $ar^{2} + br + c = 0$ has equal roots $r_{1}$, show that
            \begin{equation}
                L[e^{rt}] = a(e^{rt})'' + b(e^{rt})' + ce^{rt} = a(r - r_{1})^{2}e^{rt}
            \end{equation}
            When $r = r_{1}$, $L[e^{rt}] = 0$, therefore $e^{rt}$ is a solution to
            \begin{equation}
                L[y] = ay'' + by' + cy = 0
            \end{equation}
            \item  Then,
            \begin{alignat}{1}
                \frac{\partial}{\partial r}L[e^{rt}] &= L[\frac{\partial}{\partial r}e^{rt}]=L[te^{rt}]\\
                &= ate^{rt}(r-r_{1})^{2} + 2ae^{rt}(r-r_{1})
            \end{alignat}
            Because $r = r_{1} \implies L[te^{rt}] = 0$, $te^{rt}$ is another solution to $L[y] = 0$.
        \end{enumerate}
        Show that $e^{rt}, te^{rt}$ form a FSS.
        \begin{enumerate}[label=\alph*.]
            \item $L[e^{rt}] = 0$
            \item $L[te^{rt}] = 0$
            \begin{alignat}{1}
                (te^{rt})' &= e^{rt} + rte^{rt}\\
                (te^{rt})'' &= 2re^{rt} + r^{2}te^{rt}\\
                %&= 2re^{rt} + r^{2}te^{rt} + b(te^{rt})\\
                L[te^{rt}] &= (2re^{rt} + r^{2}te^{rt}) + a(e^{rt} + rte^{rt}) + b\\
                &= e^{rt}(2r + a) + te^{rt}(r^{2} + ar + b)
            \end{alignat}
        \end{enumerate}
    \end{example}
    \chapter{18 February 2020}
    \section{Test Corrections}
    No points were missed, however, to clear a misunderstanding:
    \begin{enumerate}
        \item[7.] Show that
        \begin{equation}
            y_{1} = t^{-1};\quad y_{2} = t^{1/2}
        \end{equation}
        form a fundamental set of solutions for
        \begin{equation}
            L[y] = 2ty'' + 3y' - \frac{1}{t}y = 0; t > 0
        \end{equation}
        Wrong:
        \begin{equation}
            L[c_{1}t^{-1} + c_{2}t^{1/2}] = 0 \implies c_{1}L[t^{-1}] + c_{2}L[t^{1/2}] = 0
        \end{equation}
        Correct:
        \begin{equation}
            L[t^{-1}] = 0;\quad L[t^{1/2}] = 0
        \end{equation}
        Then, prove that
        \begin{equation}
            W[t^{-1}, t^{1/2}] \neq 0
        \end{equation}
    \end{enumerate}
    The wrong assumption proved the principle of superposition (the linear combination of $y_{1}, y_{2}$ are also solutions to $L[y]$), however, it does not prove that $y_{1}, y_{2}$ are indeed solutions to $L[y]$.
    To correctly do the problem, one must compute the linear operator on $y_{1}$ and $y_{2}$, and ensure that they equal 0.
    \chapter{20 February 2020}
    \section{Imaginary Roots}
    Now consider a characteristic function,
    \begin{equation}
        f(r) = r^{2} + ar + b = 0
    \end{equation}
    where $r \in \CC$. The roots of $f(r) = 0$ can then be expressed by
    \begin{equation}
        r_{1,2} = \lambda \pm i\tau
    \end{equation}
    Then, what is the general solution of
    \begin{equation}
        L[y] = y'' + ay' + by = 0
    \end{equation}
    where the characteristic function yields non-real roots?
    \begin{btheorem}[Imaginary Roots]
        In the case that the solutions to $f(r) = 0$ are
        \begin{equation}
            r_{1,2} = \lambda \pm i\tau
        \end{equation}
        the general solution of the corresponding $L[y] = 0$ is given by
        \begin{equation}
            y_{1} = e^{\lambda t}\cos(\tau t);\quad y_{2} = e^{\lambda t}\sin(\tau t)
        \end{equation}
        
        The solutions $y_{1}$ and $y_{2}$ are a fundamental set of solutions.
    \end{btheorem}
    \begin{homework}
        Show that $y_{1} = e^{\lambda t}\cos(\tau t);\quad y_{2} = e^{\lambda t}\sin(\tau t)$ are solutions to $L[y] = 0$, with a characteristic function that has imaginary roots.
    \end{homework}
    \begin{bproof}[Fundamental Set]
        In \textbf{Theorem 12.1}, $y_{1} = e^{\lambda t}\cos(\tau t);\quad y_{2} = e^{\lambda t}\sin(\tau t)$
        \begin{alignat}{1}
            &W[y_{1}, y_{2}]\\
            &= \begin{vmatrix}
                e^{\lambda t}\cos(\tau t) & e^{\lambda t}\sin(\tau t)\\
                \lambda e^{\lambda t}\cos(\tau t) - \tau e^{\lambda t}\sin(\tau t) & \lambda e^{\lambda t}\sin(\tau t) + \tau e^{\lambda t}\cos(\tau t)
            \end{vmatrix}\\
            &= e^{2\lambda t}\begin{vmatrix}
                \cos(\tau t) & \sin(\tau t)\\
                \lambda \cos(\tau t) - \tau\sin(\tau t) & \lambda\sin(\tau t) + \tau\cos(\tau t)
            \end{vmatrix}\\
            &= e^{2\lambda t}[\lambda\cos(\tau t)\sin(\tau t) + \tau\cos^{2}(\tau t) - \lambda\sin(\tau t)\cos(\tau t) + \tau\sin^{2}(\tau t)]\\
            &= \tau e^{2\lambda t} \nequiv 0
        \end{alignat}
        Therefore, $y_{1,2}$ form a fundamental set of solutions.
    \end{bproof}
    \begin{example}
        Solve
        \begin{equation}
            L[y] = y'' - 2y' + 6y = 0
        \end{equation}
        The characteristic function is given by
        \begin{equation}
            f(r) = r^{2} - 2r + 6 = 0
        \end{equation}
        The roots are
        \begin{equation}
            r_{1,2} = \frac{2 \pm \sqrt{-20}}{2} = 1 \pm i\sqrt{5}
        \end{equation}
        Therefore,
        \begin{equation}
            y_{1} = e^{t}\cos\left(\sqrt{5}t\right);\quad y_{2} = e^{t}\sin(\sqrt{5}t)
        \end{equation}
        Then, the general solution can be given as
        \begin{equation}
            y_{c} = c_{1}e^{t}\cos(\sqrt{5}t) + c_{2}e^{t}\sin(\sqrt{5}t)
        \end{equation}
    \end{example}
    \np
    \begin{example}
        Solve
        \begin{equation}
            L[y] = 9y'' + 6y' + y = 0
        \end{equation}
        The characteristic function is given by
        \begin{equation}
            f(r) = r^{2} + 6y' + y = 0
        \end{equation}
        The roots are
        \begin{equation}
            (3r + 1)^{2}
        \end{equation}
        \begin{equation}
            r_{1} = r_{2} = -\frac{1}{3}
        \end{equation}
        This implies
        \begin{equation}
            y_{1} = \exp(-\frac{1}{3}t);\quad y_{2} = t\exp(-\frac{1}{3}t)
        \end{equation}
        Then, the general solution can be given as
        \begin{equation}
            y_{c} = c_{1}\exp(-\frac{1}{3}t) + c_{2}t\exp(-\frac{1}{3}t)
        \end{equation}
    \end{example}
    \chapter{25 February 2020}
    Note: Lectures from 25 February to 3 March, 2020 are not presented by Dr. Darbinyan
    \section{Nonhomogeneous SOLDEs}
    \begin{definition}[Nonhomogeneous SOLDE]
        The general form of a Nonhomogeneous SOLDE (NSOLDE) is given by
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = g(t)
        \end{equation}
    \end{definition}
    \begin{btheorem}
        Suppose that $y_{1}, y_{2}$ are solutions of
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = g(t)
        \end{equation}
        then,
        \begin{equation}
            y_{1} - y_{2} = 0
        \end{equation}
    \end{btheorem}
    \begin{bproof}
        \begin{alignat}{1}
            L[y_{1}] & = g\\
            L[y_{2}] & = g
        \end{alignat}
        Then,
        \begin{equation}
            L[y_{1}] - L[y_{2}] = L[y_{1}, y_{2}] = g - g = 0
        \end{equation}
    \end{bproof}
    \begin{btheorem}[General Solutions to NSOLDEs]
        Given the following NSOLDE
        \begin{equation}
            \label{gsnsolde}
            L[y] = y'' + p(t)y' + q(t)y = g(t)
        \end{equation}
        and its corresponding HSOLDE,
        \begin{equation}
            \label{gshsolde}
            L[y] = y'' + p(t)y' + q(t)y = 0
        \end{equation}
        The general solution involves a particular solution of \textbf{Equation \ref{gsnsolde}} consists of a particular solution and a solution of the corresponding HSODLE,
        \begin{equation}
            \label{gs}
            y = \phi(t) = C_{1}y_{1} + C_{2}y_{2} + Y
        \end{equation}
        where $y_{1}, y_{2}$ are solutions to \textbf{Equation \ref{gshsolde}}, and $Y$ is a particular solution of \textbf{Equation \ref{gsnsolde}}
    \end{btheorem}
    \begin{bproof}
        From the \textbf{Theorem 13.1}, we get
        \begin{equation}
            \phi - Y = c_{1}y_{1} + c_{2}y_{2}
        \end{equation}
        this is the same as \textbf{Equation \ref{gs}}.
    \end{bproof}
    From \textbf{Theorem  13.2}, solving NSOLDEs involves
    \begin{enumerate}
        \item Finding the general solution of the corresponding HSOLDE. (complementary solution; $y_c$)
        \item Find any particular solution, $Y$, to the NSOLDE.
        \item Then, the solution to the NSOLDE is the sum of the particular and general solutions.
    \end{enumerate}
    \np
    \section{Method of Undetermined Coefficients}
    \begin{example}
        Find a particular solution to
        \begin{equation}
            y''-3y'-4y=3e^{2t}
        \end{equation}
        The corresponding HSOLDE is given by
        \begin{equation}
            y'' - 3y' -4y = 0
        \end{equation}
        It is possible to "guess" the particular solution to a NSOLDE based on the form of $g(t)$. In this case, a reasonable guess would be
        \begin{equation}
            Y = Ae^{2t}
        \end{equation}
        Substituting $Y$ into the original equation yields
        \begin{equation}
            L[Ae^{2t}] = (Ae^{2t})'' - 3(Ae^{2t})' - 4(Ae^{2t}) = 3e^{2t}
        \end{equation}
        Solving for the undetermined coefficient,
        \begin{equation}
            (Ae^{2t})' = (2Ae^{2t}), (Ae^{2t})'' = (4Ae^{2t})
        \end{equation}
        \begin{alignat}{1}
            4Ae^{2t} - 3(2Ae^{2t}) - 4(Ae^{2t}) &= 3e^{2t}\\
            4A - 6A - 4A &= 3\\
            -6A &= 3\\
            A &= -\frac{1}{2}
        \end{alignat}
        Therefore,
        \begin{equation}
            Y = -\frac{1}{2}e^{2t}
        \end{equation}
        is a particular solution to this NSOLDE.
    \end{example}
    \np
    \begin{example}
        Find a particular solution of
        \begin{equation}
            y'' - 3y' - 4y = 2\sin(t)
        \end{equation}
        Guess,
        \begin{alignat}{1}
            Y &= A\sin(t)\\
            \implies  2\sin(t) &= -A\sin(t)-3A\cos(t)-6A\sin(t)
        \end{alignat}
        As can be seen above, the guess $A\sin(t)$ is incorrect due to the appearance of the $\cos(t)$ term, creating an open subspace. Creating a closed subspace yields
        \begin{equation}
            Y = A\cos(t) + B\sin(t)
        \end{equation}
        Then,
        \begin{alignat}{1}
            Y' &= -A\sin(t) + B\cos(t)\\
            Y'' &= -A\cos(t) + B\sin(t)\\
            L[Y] &= (-A\cos(t) + B\sin(t)) -3(-A\sin(t) + B\cos(t))\\
            &-4(A\cos(t) + B\sin(t)) = 2\sin(t)\\
            2\sin(t) &=\cos(t)(-A-3B-4A) + \sin(t)(-B+3A-4B)\\
            &\begin{cases}
                -A-3B-4A &= 0\\
                -B+3A-4B &= 2
            \end{cases}
        \end{alignat}
        By solving the linear combination,
        \begin{equation}
            A = \frac{3}{17},\quad B = -\frac{5}{17}
        \end{equation}
        Finally, a particular solution given by this method is
        \begin{equation}
            y = \frac{3}{17}\cos(t) = \frac{5}{7}\sin(t)
        \end{equation}
    \end{example}
    \np
    \begin{example}
        Find a particular solution of
        \begin{equation}
            y'' - 3y' -4y = -8e^{t}\cos(2t)
        \end{equation}
        A guess at a particular solution would be
        \begin{equation}
            Y = Ae^{t}\cos(2t) + Be^{t}\sin(2t)
        \end{equation}
        Then, substitution
        \begin{alignat}{1}
            Y' &= Ae^{t}\cos(2t)-2Ae^{t}\sin(2t) + Be^{t}\sin(2t) + 2Be^{t}\cos(2t)\\
            Y'' &= (-3A + 4B)e^{t}\cos(2t) - (4A + 3B)\sin(2t)\\
            & \begin{cases}
                10A + 2B &= 8\\
                2A-10B &= 0
            \end{cases}
        \end{alignat}
        Solving the linear combination yields
        \begin{equation}
            A = \frac{10}{13};\quad B = \frac{2}{13}
        \end{equation}
        Finally, a particular solution given by this method is
        \begin{equation}
            y = \frac{10}{13}e^{t}\cos(2t) + \frac{2}{13}e^{t}\sin(2t)
        \end{equation}
    \end{example}
    \np
    \begin{example}
        Find a particular solution of
        \begin{equation}
            \label{nsolde41}
            L[y] = y'' -3y' -4y = 3e^{2t} + 2\sin(t)
        \end{equation}
        It is possible to separate this NSOLDE into two,
        \begin{equation}
            \label{nsolde42}
            L[y] = 3e^{2t}; L[y] = 2\sin(t)
        \end{equation}
        And a particular solution to \textbf{Equation \ref{nsolde41}} is the linear combination of the solutions to the two NSOLDEs in \textbf{\ref{nsolde42}}.
        Having solved the two NSOLDEs previously,
        \begin{alignat}{1}
            Y_{1} &= -\frac{1}{2}e^{2t}\\
            Y_{2} &= -\frac{5}{17}\cos(t) + \frac{3}{17}\sin(t)
        \end{alignat}
        Then, a particular solution is given by
        \begin{equation}
            y = -\frac{1}{2}e^{2t} -\frac{5}{17}\cos(t) + \frac{3}{17}\sin(t)
        \end{equation}
    \end{example}
    \np
    \begin{example}
        Find a particular solution of
        \begin{equation}
            L[y] = y''- 3y' - 4y = 2e^{2t}
        \end{equation}
        if
        \begin{equation}
            Y = Ae^{-t};\quad Y' = -Ae^{-t};\quad Y'' = Ae^{-t}
        \end{equation}
        then,
        \begin{equation}
            L[Y] = Ae^{-t} - 3(-Ae^{-t}) - 4(Ae^{-t}) = 2e^{-t}
        \end{equation}
        When solving for A, we get $0 = 2$, which is false, therefore $Ae^{-t}$ is not a form of a particular solution.
        Then,
        \begin{equation}
            Y = Ate^{-t};\quad L[Y] = 2e^{-t}
        \end{equation}
        \begin{alignat}{1}
            L[Y] &= (Ate^{-t} - 2Ae^{-t})-3(Ae^{-t}-Ate^{-t}) - 4Ate^{-t}\\
            -5Ae^{t}&=2e^{-t}\\
            A &= -\frac{2}{5}\\
            y &= -\frac{2}{5}te^{-t}
        \end{alignat}
    \end{example}
    In the previous example, the corresponding homogeneous equation is
    \begin{equation}
        L[y] = y'' - 3y' - 4y = 0
    \end{equation}
    And the solutions to this equation are
    \begin{equation}
        y_{1} = e^{-t};\quad y_{2} = e^{4t}
    \end{equation}
    As it can be seen, the guess of $Y = Ae^{-t} = Ay_{1}$,
    \begin{equation}
        L[Ae^{-t}] = L[Ay_{1}] = AL[y_{1}] = 0
    \end{equation}
    Therefore,
    \begin{equation}
        L[Y] \neq 2e^{-t}
    \end{equation}
    \chapter{27 February 2020}
    \section{Method of Undetermined Coefficients (cont)}
    From the last lecture, we have considered
    \begin{equation}
        L[y] = y'' - 3y' + 4y = g(t)
    \end{equation}
    with the following cases for $g(t)$
    \begin{multicols}{3}
        \begin{enumerate}
            \item $g = \text{polynomial}$
            \item $g = e^{\alpha t}$
            \item $g = \sin(\alpha t)$
            \item $g = e^{\alpha t}\sin(\beta t)$
            \item $g = \alpha e^{-t}$
        \end{enumerate}
    \end{multicols}
    \begin{example}
        Given
        \begin{equation}
            L[y] = y'' -2y' + y = e^{t}
        \end{equation}
        Possible guesses following the previously considered equation and cases,
        \begin{equation}
            Y = \begin{cases}
                Ae^{t}\\
                Ate^{t}
            \end{cases}
        \end{equation}
        However, neither one of these cases work, because the corresponding homogeneous equation has solutions $y_{1} = e^{t}, y_{2} = te^{t}$. Therefore, another guess would be $At^{2}e^{t}$.
        \begin{equation}
            L[At^{2}e^{t}] \implies A = \frac{1}{2}
        \end{equation}
    \end{example}
    A general rule of thumb is to increase the order of $t$ until $L[Y] \neq 0$.
    \np
    \section{Variation of Parameters}
    What if a NSOLDE is given by
    \begin{equation}
        L[Y] = \frac{P(t)}{e^{\alpha t}}
    \end{equation}
    or some other complicated function?
    \begin{example}
        Find the general solution of
        \begin{equation}
            L[y] = y'' + 4y = 8\tan(t);\quad t\in\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)
        \end{equation}
        Solution:
        \begin{equation}
            L[Y] = 0 \implies f(r) = r^{2} + 4 = 0 \implies r_{1,2} = \pm 2i
        \end{equation}
        Then, a general solution to the CHSOLDE
        \begin{equation}
            y = c_{1}\cos(2t) + c_{2}\sin(2t)
        \end{equation}
        If the constants $c_{1,2}$ are replaced by some functions $u_{1,2}$ then,
        \begin{equation}
            y = u_{1}(t)\cos(2t) + u_{2}(t)\sin(2t)
        \end{equation}
        is a solution of the original NSOLDE.
        \begin{equation}
            y' = -2u_{1}\sin(2t) + 2u_{2}\cos(2t)+u_{1}'\cos(2t)+u_{2}'\sin(2t)
        \end{equation}
        Then, choosing a restriction and applying it yields
        \begin{equation}
            u_{1}'\cos(2t) + u_{2}'\sin(2t) = 0
        \end{equation}
        \begin{equation}
            y' = -2u_{1}\sin(2t) + 2u_{2}\cos(2t)
        \end{equation}
        \begin{equation}
            y'' = -4u_{1}\cos(2t)-4u_{2}\sin(2t)-2u_{1}'\sin(2t)+2u_{2}'\cos(2t)
        \end{equation}
        Substituting the values into the NSOLDE,
        \begin{equation}
            \begin{alignedat}{1}
                y'' + 4y = &-4u_{1}\cos(2t) - 4u_{2}\sin(2t)-2u_{1}'\sin(2t)+2u_{2}'\cos(2t)\\
                &+4u_{1}\cos(2t)+4u_{2}\sin(2t) = 8\tan(t)
            \end{alignedat}
        \end{equation}
        Solving for $u_{2}'$
        \begin{equation}
            u_{2}' = -u_{1}'\cot(2t)
        \end{equation}
        Solving for $u_{1}'$
        \begin{equation}
            u_{1}' = -\frac{8\tan(t)\sin(2t)}{2} = -8\sin^{2}t
        \end{equation}
        Plugging in $u_{1,2}$
        \begin{equation}
            u_{2}' = 4\frac{\sin(t)(2\cos^{2}(t) - 1)}{\cos(t)} = 4\sin(t)\left(2\cos(t) - \frac{1}{\cos(t)}\right)
        \end{equation}
        Then,
        \begin{equation}
            u_{1} = 4\sin(t)\cos(t)-4t + c_{1}
        \end{equation}
        \begin{equation}
            u_{2} = 4\ln(\cos(t)) - 4\cos^{2}t + c_{2}
        \end{equation}
        Finally, a solution can be written as
        \begin{equation}
            y = -2\sin(2t) - 4t\cos(2t) + 4\ln(\cos(2t))\sin(2t) + c_{1}\cos(2t) + c_{2}\sin(2t)
        \end{equation}
    \end{example}
    \begin{btheorem}
        \begin{equation}
            L[y] = y'' + p(t)y' + q(t)y = g(t)
        \end{equation}
        If $p, q, g$ are continuous on the open interval $I$; and the solutions to the corresponding HSOLDE satisfy $W[y_{1}, y_{2}] \nequiv 0$. Then, a particular solution is given by
        \begin{equation}
            Y = y_{2}\int_{t_{0}}^{t}\frac{y_{1}(s)g(s)}{W[y_{1},y_{2}](s)}\,ds -y_{1}\int_{t_{0}}^{t}\frac{y_{2}(s)g(s)}{W[y_{1},y_{2}](s)}\,ds
        \end{equation}
        $\forall t_{0} \in I$ the general solution is
        \begin{equation}
            y = c_{1}y_{1} + c_{2}y_{2} + Y
        \end{equation}
    \end{btheorem}
    \begin{bproof}
        Given
        \begin{equation}
            L[y] = y'' + py' + qy = g
        \end{equation}
        Where $p,q,g$ are continuous functions, in the case that $g = 0$, gives us a HSOLDE which has a general solution
        \begin{equation}
            y_{c} = c_{1}y_{1} + c_{2}y_{2}
        \end{equation}
        (Keep in mind that only CHSOLDEs, or cases where $p, q$ are constants have been discussed.)
        Substituting $c_{1,2}$ for $u_{1,2}$
        \begin{equation}
            y = u_{1}y_{1} + u_{2}y_{2}
        \end{equation}
    \end{bproof}
    \begin{bproof*}[14.1]
        To ensure that the solution is one of the NSOLDE and not the HSOLDE, we take the derivative
        \begin{equation}
            y' = u_{1}'y_{1} + u_{1}y_{1}' + u_{2}'y_{2} + u_{2}y_{2}'
        \end{equation}
        Setting a restriction
        \begin{equation}
            u_{1}'y_{1} + u_{2}'y_{2} = 0
        \end{equation}
        Then, $y'$ can be simplified and be differentiated once more,
        \begin{equation}
            y' = u_{1}y_{1}' + u_{2}y_{2}'
        \end{equation}
        \begin{equation}
            y'' = u_{1}'y_{1}' + u_{1}y_{1}'' + u_{2}'y_{2}' + u_{2}y_{2}''
        \end{equation}
        Then substituting for $y, y', y''$ yields
        \begin{equation}
            \begin{alignedat}{1}
                g =\ &u_{1}\left(y_{1}'' + py_{1}' + qy_{1}\right)\\
                &+u_{2}\left(y_{2}'' + py_{2}' + qy_{2}\right)\\
                &+u_{1}'y_{1}' + u_{2}'y_{2}'
            \end{alignedat}
        \end{equation}
        In the above equation, the lines with coefficients $u_{1,2}$ are equal to zero, as $y_{1,2}$ are solutions to the HSOLDE, giving
        \begin{equation}
            u_{1}'y_{1}' + u_{2}'y_{2}' = g
        \end{equation}
        Then, solving the system gives
        \begin{equation}
            u_{1}' = -\frac{y_{2}g}{W[y_{1}, y_{2}]};\quad u_{2}' = \frac{y_{1}g}{W[y_{1}, y_{2}]}
        \end{equation}
        Note that because $y_{1,2}$ form a FSS, $W[y_{1}, y_{2}] \nequiv 0$. Now to solve for $u_{1,2}$
        \begin{equation}
            u_{1} = -\int \frac{y_{2}g}{W[y_{1},y_{2}]}\,dt + c_{1};\quad u_{2} = \int \frac{y_{1}g}{W[y_{1},y_{2}]}\,dt + c_{2}
        \end{equation}
    \end{bproof*}
    \chapter{3 March 2020}
    \section{Indefinite Integrals}

    \begin{definition}[Improper Integrals]
        \begin{equation}
            \int_{a}^{\infty}f(t)\,dt = \lim_{A\to\infty}\int_{a}^{A}f(t)\,dt
        \end{equation}
        If the limit exists then it is convergent, otherwise it is considered to be divergent
    \end{definition}
    \np
    \begin{example}
        Does the following integral converge?
        \begin{equation}
            \int_{1}^{\infty} t^{-1}\,dt
        \end{equation}
        Solution:
        \begin{alignat}{1}
            \lim_{A\to\infty}\int_{1}^{A}(t^{-1})\,dt&\\
            \lim_{A\to\infty}\left(\ln(t)|_{1}^{A}\right) &= \infty
        \end{alignat}
        Therefore, it is divergent.
    \end{example}
    \begin{example}
        For what values does the following integral converge?
        \begin{alignat}{1}
            &\int_{0}^{\infty}e^{ct}\,dt\\
            =&\lim_{A\to\infty}\int_{0}^{A}e^{ct}\,dt\\
            =&\lim_{A\to\infty}\frac{1}{c}e^{ct}\bigg|_{0}^{A}\\
            =&\lim_{A\to\infty}\left[\frac{1}{c}e^{ct}-\frac{1}{c}\right]\\
            =& \frac{1}{c}, c < 0
        \end{alignat}
    \end{example}
    \np
    \begin{example}
        For what values of $p$ does the integral converge?
        \begin{alignat}{1}
            &\int_{1}^{\infty}t^{-p}\,dt\\
            =&\lim_{A\to\infty}\int_{1}^{A}t^{-p}\,dt\\
            =&\lim_{A\to\infty}\frac{1}{1-p}t^{1-p}\bigg|_{1}^{A}\\
            =&\lim_{A\to\infty}\frac{1}{1-p}\left(A^{1-p}-1\right), p \neq -1\\
            =& \frac{1}{p - 1}, p > 1
        \end{alignat}
    \end{example}
    % TODO: Write stuff about piecewise continuity here, was not covered in original lecture notes
    \section{Laplace Transformation}
    In algebra, we were introduced to the concept of factorization,
    \begin{alignat}{1}
        x^{2} + 4x + 3 &= 0 \\
        (x + 3)(x + 1) &= 0 \\
        \implies x \in \{-2, -1\}
    \end{alignat}
    Factorization is useful because it was a tool to solve for the roots of a polynomial. The Laplace tranformation can also be thought of as a tool that would help in solving ODEs.

    \begin{definition}
        The \textbf{Laplace Transformation} is an integral transformation, given by
        \begin{equation}
            \lp{f(t)} = F(s) = \int_{0}^{\infty}e^{-st}f(t)\,dt
        \end{equation}
    \end{definition}

    \begin{btheorem}
        Suppose that
        \begin{enumerate}
            \item $f$ is piecewise continuous on the intervals $t\in[0,A], A \in \RR^{+}$
            \item $\exists (k, a, M), (K, M) > 0, |f(t)| \leq ke^{at}, t \geq M$
        \end{enumerate}
        Then, $\forall s > a, F(s)$
    \end{btheorem}
    \np
    \begin{example} % TODO: workout this example
        Find \begin{equation}
            \lp{1} = \frac{1}{s^{2}}
        \end{equation}
    \end{example}

    \chapter*{5 - 22 March 2020}
    Lectures on dates 5, 17, 22 March were cancelled.
    \chapter{24 March 2020}
    \chapter{29 March 2020}
    \chapter{31 March 2020}
    \chapter{2 April 2020}
\end{document}